import chromadb
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
import uuid
import os

from .config import CHROMA_PERSIST_DIR, EMBEDDING_MODEL

class VectorStore:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB –∏ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è ChromaDB –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(CHROMA_PERSIST_DIR, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ChromaDB
        try:
            self.chroma_client = chromadb.PersistentClient(
                path=str(CHROMA_PERSIST_DIR)
            )
            print("‚úÖ ChromaDB –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB: {e}")
            raise
        
        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
        try:
            self.collection = self.chroma_client.get_collection("history_textbooks")
            print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è, —á–∞–Ω–∫–æ–≤: {self.collection.count()}")
        except:
            self.collection = self.chroma_client.create_collection(
                name="history_textbooks",
                metadata={"hnsw:space": "cosine"}
            )
            print("‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {EMBEDDING_MODEL}")
        try:
            self.embedding_model = SentenceTransformer(EMBEDDING_MODEL)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {self.embedding_model.get_sentence_embedding_dimension()}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            print("üîÑ –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫—É—é –º–æ–¥–µ–ª—å...")
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∞—è –º–æ–¥–µ–ª—å")
    
    def add_chunks(self, chunks: List[Dict[str, Any]], doc_id: int) -> List[str]:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫–∏ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ ID —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        """
        if not chunks:
            return []
        
        embeddings = []
        metadatas = []
        ids = []
        documents = []
        
        print(f"üîÑ –î–æ–±–∞–≤–ª—è–µ–º {len(chunks)} —á–∞–Ω–∫–æ–≤ –≤ ChromaDB...")
        
        for i, chunk in enumerate(chunks):
            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                chunk_id = f"doc{doc_id}_chunk{i}_{uuid.uuid4().hex[:8]}"
                
                # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
                embedding = self.embedding_model.encode(chunk["content"]).tolist()
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å—Ç—Ä–æ–∫–∞–º–∏)
                metadata = {
                    "doc_id": str(doc_id),
                    "chunk_index": str(i),
                    "page_number": str(chunk.get("page_number", 1)),
                    "chapter": str(chunk.get("chapter", ""))[:100],
                    "paragraph": str(chunk.get("paragraph", ""))[:100],
                    "section_title": str(chunk.get("section_title", ""))[:200]
                }
                
                embeddings.append(embedding)
                metadatas.append(metadata)
                ids.append(chunk_id)
                documents.append(chunk["content"][:1000])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è ChromaDB
                
                if i % 50 == 0 and i > 0:
                    print(f"  ‚è≥ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/{len(chunks)} —á–∞–Ω–∫–æ–≤")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —á–∞–Ω–∫–∞ {i}: {e}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é –±–∞—Ç—á–∞–º–∏ –ø–æ 100
        batch_size = 100
        added_count = 0
        
        for i in range(0, len(embeddings), batch_size):
            try:
                batch_end = min(i + batch_size, len(embeddings))
                self.collection.add(
                    embeddings=embeddings[i:batch_end],
                    metadatas=metadatas[i:batch_end],
                    ids=ids[i:batch_end],
                    documents=documents[i:batch_end]
                )
                added_count += (batch_end - i)
                print(f"  ‚úì –î–æ–±–∞–≤–ª–µ–Ω –±–∞—Ç—á {i//batch_size + 1}/{(len(embeddings)-1)//batch_size + 1}")
            except Exception as e:
                print(f"  ‚úó –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –±–∞—Ç—á–∞: {e}")
                # –ü—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å –ø–æ –æ–¥–Ω–æ–º—É
                for j in range(i, min(i + batch_size, len(embeddings))):
                    try:
                        self.collection.add(
                            embeddings=[embeddings[j]],
                            metadatas=[metadatas[j]],
                            ids=[ids[j]],
                            documents=[documents[j]]
                        )
                        added_count += 1
                    except Exception as e2:
                        print(f"    ‚úó –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —á–∞–Ω–∫–∞ {j}: {e2}")
        
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {added_count}/{len(chunks)} —á–∞–Ω–∫–æ–≤ –≤ ChromaDB")
        return ids[:added_count]
    
    def get_collection_stats(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            count = self.collection.count()
            return {
                "total_chunks": count,
                "collection_name": self.collection.name,
                "status": "active"
            }
        except Exception as e:
            return {
                "total_chunks": 0,
                "collection_name": "history_textbooks",
                "status": f"error: {e}"
            }
    
    def search(self, query: str, n_results: int = 5) -> Optional[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —á–∞–Ω–∫–æ–≤"""
        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.embedding_model.encode(query).tolist()
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —á–∞–Ω–∫–∏
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                include=["metadatas", "documents", "distances"]
            )
            
            return results
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def delete_document(self, doc_id: int):
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        try:
            self.collection.delete(
                where={"doc_id": str(doc_id)}
            )
            print(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id} –∏–∑ ChromaDB")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id}: {e}")