import re
from pathlib import Path
import PyPDF2
import pdfplumber
from typing import List, Dict, Any, Tuple
import tiktoken

class DocumentProcessor:
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        # –î–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.encoder = tiktoken.get_encoding("cl100k_base")
    
    def extract_text_from_pdf(self, pdf_path: str) -> Tuple[str, Dict[int, str]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ —Å–ª–æ–≤–∞—Ä—å {—Å—Ç—Ä–∞–Ω–∏—Ü–∞: —Ç–µ–∫—Å—Ç_—Å—Ç—Ä–∞–Ω–∏—Ü—ã}
        """
        full_text = []
        pages_text = {}
        
        # –ü—Ä–æ–±—É–µ–º pdfplumber (–ª—É—á—à–µ –¥–ª—è —Å–ª–æ–∂–Ω–æ–π –≤–µ—Ä—Å—Ç–∫–∏)
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for i, page in enumerate(pdf.pages, 1):
                    text = page.extract_text() or ""
                    pages_text[i] = text
                    full_text.append(text)
            print(f"‚úÖ PDFplumber: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(pages_text)} —Å—Ç—Ä–∞–Ω–∏—Ü")
        except Exception as e:
            print(f"‚ö†Ô∏è PDFplumber –æ—à–∏–±–∫–∞: {e}, –ø—Ä–æ–±—É–µ–º PyPDF2")
            
            # Fallback –Ω–∞ PyPDF2
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                for i, page in enumerate(reader.pages, 1):
                    text = page.extract_text() or ""
                    pages_text[i] = text
                    full_text.append(text)
        
        return "\n".join(full_text), pages_text
    
    def detect_structure(self, text: str, pages_text: Dict[int, str]) -> Dict[str, Any]:
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —É—á–µ–±–Ω–∏–∫–∞:
        –≥–ª–∞–≤—ã, –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, –∑–∞–≥–æ–ª–æ–≤–∫–∏.
        """
        structure = {
            "chapters": [],
            "paragraphs": []
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        chapter_patterns = [
            r'–ì–ª–∞–≤–∞\s*(\d+|[IVXLCDM]+)\.?\s*(.*?)(?=\n|$)',
            r'–†–∞–∑–¥–µ–ª\s*(\d+|[IVXLCDM]+)\.?\s*(.*?)(?=\n|$)',
            r'–ß–∞—Å—Ç—å\s*(\d+|[IVXLCDM]+)\.?\s*(.*?)(?=\n|$)'
        ]
        
        paragraph_patterns = [
            r'¬ß\s*(\d+|[IVXLCDM]+)\.?\s*(.*?)(?=\n|$)',
            r'–ü–∞—Ä–∞–≥—Ä–∞—Ñ\s*(\d+|[IVXLCDM]+)\.?\s*(.*?)(?=\n|$)'
        ]
        
        # –ò—â–µ–º –≥–ª–∞–≤—ã
        for pattern in chapter_patterns:
            chapters = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            if chapters:
                structure["chapters"] = [{"number": num, "title": title.strip()} for num, title in chapters]
                break
        
        # –ò—â–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        for pattern in paragraph_patterns:
            paragraphs = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
            if paragraphs:
                structure["paragraphs"] = [{"number": num, "title": title.strip()} for num, title in paragraphs]
                break
        
        return structure
    
    def create_chunks(self, text: str, pages_text: Dict[int, str], metadata: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å —É–º–Ω—ã–º –¥–µ–ª–µ–Ω–∏–µ–º –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º.
        """
        chunks = []
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º (¬ß)
        paragraphs = re.split(r'(?=¬ß\s*\d+)|(?=\n\s*\n)', text)
        
        current_chunk = ""
        current_chunk_start_page = 1
        chunk_index = 0
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è —ç—Ç–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
            page_num = self._find_page_for_text(paragraph, pages_text)
            
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ + –Ω–æ–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—Ç —Ä–∞–∑–º–µ—Ä
            if len(current_chunk) + len(paragraph) < self.chunk_size:
                current_chunk += paragraph + "\n"
            else:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫
                if current_chunk:
                    chunk_metadata = self._extract_chunk_metadata(current_chunk, metadata)
                    chunks.append({
                        "content": current_chunk.strip(),
                        "page_number": current_chunk_start_page,
                        "chapter": chunk_metadata.get("chapter", ""),
                        "paragraph": chunk_metadata.get("paragraph", ""),
                        "section_title": chunk_metadata.get("title", ""),
                        "chunk_index": chunk_index
                    })
                    chunk_index += 1
                
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫
                current_chunk = paragraph + "\n"
                current_chunk_start_page = page_num or current_chunk_start_page
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
        if current_chunk:
            chunk_metadata = self._extract_chunk_metadata(current_chunk, metadata)
            chunks.append({
                "content": current_chunk.strip(),
                "page_number": current_chunk_start_page,
                "chapter": chunk_metadata.get("chapter", ""),
                "paragraph": chunk_metadata.get("paragraph", ""),
                "section_title": chunk_metadata.get("title", ""),
                "chunk_index": chunk_index
            })
        
        print(f"üìÑ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")
        return chunks
    
    def _find_page_for_text(self, text: str, pages_text: Dict[int, str]) -> int:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–π –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Ç–µ–∫—Å—Ç"""
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        sample = text[:50].strip()
        for page_num, page_content in pages_text.items():
            if sample in page_content:
                return page_num
        return 1  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ç—Ä–∞–Ω–∏—Ü–∞ 1
    
    def _extract_chunk_metadata(self, chunk: str, global_metadata: Dict[str, Any]) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —á–∞–Ω–∫–∞"""
        metadata = {
            "chapter": "",
            "paragraph": "",
            "title": ""
        }
        
        # –ò—â–µ–º –≥–ª–∞–≤—É –≤ —Ç–µ–∫—Å—Ç–µ —á–∞–Ω–∫–∞
        chapter_match = re.search(r'–ì–ª–∞–≤–∞\s*(\d+|[IVXLCDM]+)', chunk, re.IGNORECASE)
        if chapter_match:
            metadata["chapter"] = chapter_match.group(0)
        
        # –ò—â–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ
        paragraph_match = re.search(r'¬ß\s*(\d+|[IVXLCDM]+)', chunk, re.IGNORECASE)
        if paragraph_match:
            metadata["paragraph"] = paragraph_match.group(0)
            
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å–ª–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
            title_match = re.search(r'¬ß\s*\d+\.?\s*(.*?)(?=\n|$)', chunk)
            if title_match:
                metadata["title"] = title_match.group(1).strip()
        
        return metadata
    
    def process_document(self, file_path: str, filename: str) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
        """
        print(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É: {filename}")
        
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        full_text, pages_text = self.extract_text_from_pdf(file_path)
        print(f"üìñ –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(full_text)}")
        
        # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        structure = self.detect_structure(full_text, pages_text)
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤: {len(structure['chapters'])}")
        print(f"üìë –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {len(structure['paragraphs'])}")
        
        # 3. –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏
        chunks = self.create_chunks(full_text, pages_text, structure)
        
        return {
            "filename": filename,
            "total_chars": len(full_text),
            "total_pages": len(pages_text),
            "chapters": structure["chapters"],
            "paragraphs": structure["paragraphs"],
            "chunks": chunks
        }